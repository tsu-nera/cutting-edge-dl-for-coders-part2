{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla GAN for MNIST (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    import torch.cuda as t\n",
    "else:\n",
    "    import torch as t\n",
    "\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import numpy as np\n",
    "from numpy.random import uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist datasetの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs,nz = 100,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/mnist', train=True, download=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=bs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Discriminater'''\n",
    "class netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(netD, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(784, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 784)\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "'''Generator'''\n",
    "class netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(netG, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(100, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(bs,nz)\n",
    "        x = self.main(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criteion = nn.BCELoss()\n",
    "net_D = netD()\n",
    "net_G = netG()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    D = net_D.cuda()\n",
    "    G = net_G.cuda()\n",
    "    criteion = criteion.cuda()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(net_D.parameters(), lr = 1e-4)\n",
    "optimizerG = optim.Adam(net_G.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_gen(G, n_ex=16):\n",
    "    plot_multi(G.predict(noise(n_ex)).reshape(n_ex, 28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noise(bs): return np.random.rand(bs,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = t.FloatTensor(bs, 1, 28, 28)\n",
    "noise = t.FloatTensor(uniform(0,1,(bs, 100, 1, 1)))\n",
    "fixed_noise = t.FloatTensor(bs, 100, 1, 1).normal_(0, 1)\n",
    "label = t.FloatTensor(bs)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "input = Variable(input)\n",
    "label = Variable(label)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "niter = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/4000][0/600] Loss_D: 1.3861 Loss_G: 0.7312 D(x): 0.4991 D(G(z)): 0.4990 / 0.4814\n",
      "[0/4000][100/600] Loss_D: 0.4276 Loss_G: 2.4578 D(x): 0.7695 D(G(z)): 0.1361 / 0.1018\n",
      "[0/4000][200/600] Loss_D: 0.4214 Loss_G: 2.1539 D(x): 0.8091 D(G(z)): 0.1721 / 0.1161\n",
      "[0/4000][300/600] Loss_D: 0.2059 Loss_G: 3.3204 D(x): 0.8802 D(G(z)): 0.0600 / 0.0364\n",
      "[0/4000][400/600] Loss_D: 0.0780 Loss_G: 3.9904 D(x): 0.9672 D(G(z)): 0.0423 / 0.0195\n",
      "[0/4000][500/600] Loss_D: 0.0637 Loss_G: 4.3640 D(x): 0.9655 D(G(z)): 0.0244 / 0.0130\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vutils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-8fea709110cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png'\n\u001b[0m\u001b[1;32m     47\u001b[0m                               % ('output', epoch),normalize=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vutils' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real (data)\n",
    "        net_D.zero_grad()\n",
    "        real, _ = data\n",
    "        input.data.resize_(real.size()).copy_(real)\n",
    "        label.data.resize_(bs).fill_(real_label)\n",
    "\n",
    "        output = net_D(input)\n",
    "        errD_real = criteion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        #train with fake (generated)\n",
    "        noise.data.resize_(bs, 100, 1, 1)\n",
    "        noise.data.normal_(0, 1)\n",
    "        fake = net_G(noise)\n",
    "        label.data.fill_(fake_label)\n",
    "        output = net_D(fake.detach())\n",
    "        errD_fake = criteion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        net_G.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = net_D(fake)\n",
    "        errG = criteion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.data.mean()\n",
    "        optimizerG.step()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "                 % (epoch, niter, i, len(dataloader),\n",
    "                   errD.data[0], errG.data[0],  D_x, D_G_z1, D_G_z2))\n",
    "    if epoch % 10 == 0:\n",
    "        fake = net_G(fixed_noise)\n",
    "        vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png'\n",
    "                              % ('output', epoch),normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "83px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
