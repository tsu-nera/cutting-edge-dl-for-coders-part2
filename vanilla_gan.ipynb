{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla GAN for MNIST (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    import torch.cuda as t\n",
    "else:\n",
    "    import torch as t\n",
    "\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist datasetの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/mnist', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=bs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Discriminater'''\n",
    "class netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(netD, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(784, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 784)\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "'''Generator'''\n",
    "class netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(netG, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(100, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(bs,100)\n",
    "        x = self.main(x)\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criteion = nn.BCELoss()\n",
    "net_D = netD()\n",
    "net_G = netG()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    D = net_D.cuda()\n",
    "    G = net_G.cuda()\n",
    "    criteion = criteion.cuda()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(net_D.parameters(), lr = 1e-4)\n",
    "optimizerG = optim.Adam(net_G.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = t.FloatTensor(bs, 1, 28, 28)\n",
    "noise = t.FloatTensor(uniform(0,1,(bs, 100, 1, 1)))\n",
    "fixed_noise = t.FloatTensor(bs, 100, 1, 1).normal_(0, 1)\n",
    "label = t.FloatTensor(bs)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "input = Variable(input)\n",
    "label = Variable(label)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "niter = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/4000][0/600] Loss_D: 1.3774 Loss_G: 0.7734 D(x): 0.4849 D(G(z)): 0.4798 / 0.4614\n",
      "[0/4000][100/600] Loss_D: 0.4435 Loss_G: 2.5407 D(x): 0.7520 D(G(z)): 0.1298 / 0.0979\n",
      "[0/4000][200/600] Loss_D: 0.3307 Loss_G: 2.3395 D(x): 0.8486 D(G(z)): 0.1452 / 0.0966\n",
      "[0/4000][300/600] Loss_D: 0.2424 Loss_G: 3.3446 D(x): 0.8489 D(G(z)): 0.0564 / 0.0354\n",
      "[0/4000][400/600] Loss_D: 0.0658 Loss_G: 4.1486 D(x): 0.9686 D(G(z)): 0.0284 / 0.0162\n",
      "[0/4000][500/600] Loss_D: 0.0548 Loss_G: 4.4317 D(x): 0.9709 D(G(z)): 0.0225 / 0.0120\n",
      "[1/4000][0/600] Loss_D: 0.0952 Loss_G: 4.8037 D(x): 0.9463 D(G(z)): 0.0218 / 0.0084\n",
      "[1/4000][100/600] Loss_D: 0.0744 Loss_G: 5.2767 D(x): 0.9725 D(G(z)): 0.0189 / 0.0054\n",
      "[1/4000][200/600] Loss_D: 0.1847 Loss_G: 4.5582 D(x): 0.9241 D(G(z)): 0.0299 / 0.0110\n",
      "[1/4000][300/600] Loss_D: 0.0385 Loss_G: 4.9896 D(x): 0.9814 D(G(z)): 0.0149 / 0.0069\n",
      "[1/4000][400/600] Loss_D: 0.0217 Loss_G: 4.8109 D(x): 0.9934 D(G(z)): 0.0147 / 0.0084\n",
      "[1/4000][500/600] Loss_D: 0.0118 Loss_G: 5.6721 D(x): 0.9940 D(G(z)): 0.0055 / 0.0035\n",
      "[2/4000][0/600] Loss_D: 0.0204 Loss_G: 5.1875 D(x): 0.9904 D(G(z)): 0.0105 / 0.0058\n",
      "[2/4000][100/600] Loss_D: 0.0306 Loss_G: 5.2118 D(x): 0.9855 D(G(z)): 0.0108 / 0.0056\n",
      "[2/4000][200/600] Loss_D: 0.0172 Loss_G: 5.6072 D(x): 0.9932 D(G(z)): 0.0102 / 0.0040\n",
      "[2/4000][300/600] Loss_D: 0.0056 Loss_G: 6.3004 D(x): 0.9978 D(G(z)): 0.0034 / 0.0019\n",
      "[2/4000][400/600] Loss_D: 0.0148 Loss_G: 5.9962 D(x): 0.9915 D(G(z)): 0.0038 / 0.0025\n",
      "[2/4000][500/600] Loss_D: 0.0046 Loss_G: 6.5175 D(x): 0.9978 D(G(z)): 0.0023 / 0.0015\n",
      "[3/4000][0/600] Loss_D: 0.0075 Loss_G: 6.4266 D(x): 0.9955 D(G(z)): 0.0025 / 0.0016\n",
      "[3/4000][100/600] Loss_D: 0.0039 Loss_G: 6.5081 D(x): 0.9984 D(G(z)): 0.0022 / 0.0015\n",
      "[3/4000][200/600] Loss_D: 0.0193 Loss_G: 6.0765 D(x): 0.9865 D(G(z)): 0.0030 / 0.0024\n",
      "[3/4000][300/600] Loss_D: 0.0052 Loss_G: 6.4796 D(x): 0.9973 D(G(z)): 0.0023 / 0.0015\n",
      "[3/4000][400/600] Loss_D: 0.0185 Loss_G: 5.8766 D(x): 0.9876 D(G(z)): 0.0043 / 0.0031\n",
      "[3/4000][500/600] Loss_D: 0.0157 Loss_G: 5.1374 D(x): 0.9927 D(G(z)): 0.0082 / 0.0061\n",
      "[4/4000][0/600] Loss_D: 0.0199 Loss_G: 5.7099 D(x): 0.9906 D(G(z)): 0.0101 / 0.0035\n",
      "[4/4000][100/600] Loss_D: 0.0237 Loss_G: 5.1928 D(x): 0.9912 D(G(z)): 0.0111 / 0.0057\n",
      "[4/4000][200/600] Loss_D: 0.0082 Loss_G: 6.1906 D(x): 0.9980 D(G(z)): 0.0061 / 0.0021\n",
      "[4/4000][300/600] Loss_D: 0.0095 Loss_G: 5.6986 D(x): 0.9988 D(G(z)): 0.0083 / 0.0035\n",
      "[4/4000][400/600] Loss_D: 0.0070 Loss_G: 7.1436 D(x): 0.9950 D(G(z)): 0.0017 / 0.0008\n",
      "[4/4000][500/600] Loss_D: 0.0188 Loss_G: 6.3601 D(x): 0.9910 D(G(z)): 0.0027 / 0.0018\n",
      "[5/4000][0/600] Loss_D: 0.0034 Loss_G: 6.8444 D(x): 0.9999 D(G(z)): 0.0033 / 0.0011\n",
      "[5/4000][100/600] Loss_D: 0.0163 Loss_G: 5.5472 D(x): 0.9920 D(G(z)): 0.0064 / 0.0041\n",
      "[5/4000][200/600] Loss_D: 0.0048 Loss_G: 6.2294 D(x): 0.9989 D(G(z)): 0.0037 / 0.0020\n",
      "[5/4000][300/600] Loss_D: 0.0023 Loss_G: 6.9944 D(x): 0.9995 D(G(z)): 0.0017 / 0.0010\n",
      "[5/4000][400/600] Loss_D: 0.0074 Loss_G: 6.3733 D(x): 0.9963 D(G(z)): 0.0031 / 0.0018\n",
      "[5/4000][500/600] Loss_D: 0.0092 Loss_G: 7.1238 D(x): 0.9941 D(G(z)): 0.0015 / 0.0009\n",
      "[6/4000][0/600] Loss_D: 0.0050 Loss_G: 5.8230 D(x): 0.9998 D(G(z)): 0.0048 / 0.0031\n",
      "[6/4000][100/600] Loss_D: 0.0041 Loss_G: 6.4950 D(x): 0.9984 D(G(z)): 0.0025 / 0.0016\n",
      "[6/4000][200/600] Loss_D: 0.0088 Loss_G: 6.4044 D(x): 0.9951 D(G(z)): 0.0030 / 0.0019\n",
      "[6/4000][300/600] Loss_D: 0.0058 Loss_G: 6.5578 D(x): 0.9978 D(G(z)): 0.0035 / 0.0018\n",
      "[6/4000][400/600] Loss_D: 0.0098 Loss_G: 5.1840 D(x): 0.9994 D(G(z)): 0.0092 / 0.0059\n",
      "[6/4000][500/600] Loss_D: 0.0021 Loss_G: 7.2978 D(x): 0.9998 D(G(z)): 0.0019 / 0.0009\n",
      "[7/4000][0/600] Loss_D: 0.0078 Loss_G: 6.1279 D(x): 0.9993 D(G(z)): 0.0070 / 0.0035\n",
      "[7/4000][100/600] Loss_D: 0.0033 Loss_G: 6.5352 D(x): 0.9996 D(G(z)): 0.0028 / 0.0016\n",
      "[7/4000][200/600] Loss_D: 0.0034 Loss_G: 6.2562 D(x): 1.0000 D(G(z)): 0.0034 / 0.0020\n",
      "[7/4000][300/600] Loss_D: 0.0053 Loss_G: 6.3146 D(x): 0.9994 D(G(z)): 0.0047 / 0.0023\n",
      "[7/4000][400/600] Loss_D: 0.0070 Loss_G: 5.8363 D(x): 0.9998 D(G(z)): 0.0067 / 0.0032\n",
      "[7/4000][500/600] Loss_D: 0.0056 Loss_G: 6.0468 D(x): 0.9996 D(G(z)): 0.0052 / 0.0025\n",
      "[8/4000][0/600] Loss_D: 0.0159 Loss_G: 6.1049 D(x): 0.9923 D(G(z)): 0.0052 / 0.0028\n",
      "[8/4000][100/600] Loss_D: 0.0117 Loss_G: 6.1046 D(x): 0.9945 D(G(z)): 0.0038 / 0.0028\n",
      "[8/4000][200/600] Loss_D: 0.0063 Loss_G: 6.3023 D(x): 0.9990 D(G(z)): 0.0052 / 0.0023\n",
      "[8/4000][300/600] Loss_D: 0.0017 Loss_G: 7.2443 D(x): 0.9998 D(G(z)): 0.0015 / 0.0008\n",
      "[8/4000][400/600] Loss_D: 0.0030 Loss_G: 6.5861 D(x): 0.9998 D(G(z)): 0.0028 / 0.0016\n",
      "[8/4000][500/600] Loss_D: 0.0029 Loss_G: 6.8881 D(x): 0.9999 D(G(z)): 0.0029 / 0.0014\n",
      "[9/4000][0/600] Loss_D: 0.0011 Loss_G: 8.4126 D(x): 0.9997 D(G(z)): 0.0008 / 0.0003\n",
      "[9/4000][100/600] Loss_D: 0.0011 Loss_G: 8.7539 D(x): 1.0000 D(G(z)): 0.0010 / 0.0005\n",
      "[9/4000][200/600] Loss_D: 0.0031 Loss_G: 8.1306 D(x): 0.9979 D(G(z)): 0.0008 / 0.0004\n",
      "[9/4000][300/600] Loss_D: 0.0039 Loss_G: 6.9073 D(x): 0.9999 D(G(z)): 0.0038 / 0.0018\n",
      "[9/4000][400/600] Loss_D: 0.0033 Loss_G: 6.6056 D(x): 0.9996 D(G(z)): 0.0029 / 0.0019\n",
      "[9/4000][500/600] Loss_D: 0.0069 Loss_G: 7.0539 D(x): 0.9961 D(G(z)): 0.0021 / 0.0012\n",
      "[10/4000][0/600] Loss_D: 0.0059 Loss_G: 7.3825 D(x): 0.9974 D(G(z)): 0.0032 / 0.0013\n",
      "[10/4000][100/600] Loss_D: 0.0028 Loss_G: 6.9515 D(x): 1.0000 D(G(z)): 0.0028 / 0.0014\n",
      "[10/4000][200/600] Loss_D: 0.0033 Loss_G: 7.7476 D(x): 0.9989 D(G(z)): 0.0021 / 0.0011\n",
      "[10/4000][300/600] Loss_D: 0.0025 Loss_G: 7.2733 D(x): 1.0000 D(G(z)): 0.0025 / 0.0010\n",
      "[10/4000][400/600] Loss_D: 0.0023 Loss_G: 6.5245 D(x): 0.9999 D(G(z)): 0.0021 / 0.0018\n",
      "[10/4000][500/600] Loss_D: 0.0011 Loss_G: 7.4187 D(x): 1.0000 D(G(z)): 0.0011 / 0.0008\n",
      "[11/4000][0/600] Loss_D: 0.0027 Loss_G: 7.9910 D(x): 0.9999 D(G(z)): 0.0026 / 0.0006\n",
      "[11/4000][100/600] Loss_D: 0.0037 Loss_G: 7.8381 D(x): 0.9983 D(G(z)): 0.0020 / 0.0007\n",
      "[11/4000][200/600] Loss_D: 0.0015 Loss_G: 8.4313 D(x): 1.0000 D(G(z)): 0.0014 / 0.0003\n",
      "[11/4000][300/600] Loss_D: 0.0041 Loss_G: 8.3181 D(x): 0.9971 D(G(z)): 0.0008 / 0.0005\n",
      "[11/4000][400/600] Loss_D: 0.0018 Loss_G: 9.2507 D(x): 0.9996 D(G(z)): 0.0014 / 0.0004\n",
      "[11/4000][500/600] Loss_D: 0.0001 Loss_G: 10.4236 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[12/4000][0/600] Loss_D: 0.0001 Loss_G: 11.2132 D(x): 1.0000 D(G(z)): 0.0001 / 0.0000\n",
      "[12/4000][100/600] Loss_D: 0.0049 Loss_G: 8.5954 D(x): 0.9963 D(G(z)): 0.0007 / 0.0004\n",
      "[12/4000][200/600] Loss_D: 0.0010 Loss_G: 8.2567 D(x): 1.0000 D(G(z)): 0.0010 / 0.0004\n",
      "[12/4000][300/600] Loss_D: 0.0016 Loss_G: 7.6023 D(x): 0.9999 D(G(z)): 0.0015 / 0.0007\n",
      "[12/4000][400/600] Loss_D: 0.0114 Loss_G: 8.9167 D(x): 0.9933 D(G(z)): 0.0003 / 0.0002\n",
      "[12/4000][500/600] Loss_D: 0.0027 Loss_G: 8.0427 D(x): 0.9985 D(G(z)): 0.0012 / 0.0010\n",
      "[13/4000][0/600] Loss_D: 0.0014 Loss_G: 7.9407 D(x): 1.0000 D(G(z)): 0.0014 / 0.0007\n",
      "[13/4000][100/600] Loss_D: 0.0000 Loss_G: 12.8441 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[13/4000][200/600] Loss_D: 0.0033 Loss_G: 7.0721 D(x): 1.0000 D(G(z)): 0.0033 / 0.0011\n",
      "[13/4000][300/600] Loss_D: 0.0679 Loss_G: 7.9982 D(x): 0.9801 D(G(z)): 0.0003 / 0.0005\n",
      "[13/4000][400/600] Loss_D: 0.0016 Loss_G: 9.0502 D(x): 0.9998 D(G(z)): 0.0013 / 0.0003\n",
      "[13/4000][500/600] Loss_D: 0.0007 Loss_G: 9.3152 D(x): 0.9999 D(G(z)): 0.0006 / 0.0002\n",
      "[14/4000][0/600] Loss_D: 0.0058 Loss_G: 8.0410 D(x): 0.9996 D(G(z)): 0.0053 / 0.0023\n",
      "[14/4000][100/600] Loss_D: 0.0023 Loss_G: 8.0422 D(x): 1.0000 D(G(z)): 0.0023 / 0.0010\n",
      "[14/4000][200/600] Loss_D: 0.0003 Loss_G: 9.9924 D(x): 1.0000 D(G(z)): 0.0003 / 0.0001\n",
      "[14/4000][300/600] Loss_D: 0.0242 Loss_G: 11.0997 D(x): 0.9908 D(G(z)): 0.0001 / 0.0001\n",
      "[14/4000][400/600] Loss_D: 0.0002 Loss_G: 11.5158 D(x): 0.9999 D(G(z)): 0.0001 / 0.0000\n",
      "[14/4000][500/600] Loss_D: 0.0050 Loss_G: 9.2287 D(x): 0.9965 D(G(z)): 0.0007 / 0.0002\n",
      "[15/4000][0/600] Loss_D: 0.0001 Loss_G: 12.9008 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[15/4000][100/600] Loss_D: 0.0013 Loss_G: 8.3123 D(x): 1.0000 D(G(z)): 0.0013 / 0.0004\n",
      "[15/4000][200/600] Loss_D: 0.0010 Loss_G: 9.0883 D(x): 1.0000 D(G(z)): 0.0010 / 0.0004\n",
      "[15/4000][300/600] Loss_D: 0.0009 Loss_G: 9.3353 D(x): 0.9999 D(G(z)): 0.0008 / 0.0003\n",
      "[15/4000][400/600] Loss_D: 0.0020 Loss_G: 8.5247 D(x): 0.9988 D(G(z)): 0.0008 / 0.0005\n",
      "[15/4000][500/600] Loss_D: 0.0011 Loss_G: 9.5346 D(x): 0.9995 D(G(z)): 0.0006 / 0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/4000][0/600] Loss_D: 0.0010 Loss_G: 8.5918 D(x): 0.9995 D(G(z)): 0.0004 / 0.0003\n",
      "[16/4000][100/600] Loss_D: 0.0002 Loss_G: 9.4420 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[16/4000][200/600] Loss_D: 0.0243 Loss_G: 8.0666 D(x): 0.9909 D(G(z)): 0.0009 / 0.0006\n",
      "[16/4000][300/600] Loss_D: 0.0016 Loss_G: 8.6173 D(x): 0.9999 D(G(z)): 0.0014 / 0.0013\n",
      "[16/4000][400/600] Loss_D: 0.0006 Loss_G: 9.5689 D(x): 0.9999 D(G(z)): 0.0006 / 0.0004\n",
      "[16/4000][500/600] Loss_D: 0.0007 Loss_G: 8.7949 D(x): 1.0000 D(G(z)): 0.0007 / 0.0003\n",
      "[17/4000][0/600] Loss_D: 0.0001 Loss_G: 11.7579 D(x): 1.0000 D(G(z)): 0.0001 / 0.0000\n",
      "[17/4000][100/600] Loss_D: 0.0020 Loss_G: 7.7364 D(x): 1.0000 D(G(z)): 0.0020 / 0.0012\n",
      "[17/4000][200/600] Loss_D: 0.0007 Loss_G: 8.1546 D(x): 1.0000 D(G(z)): 0.0007 / 0.0004\n",
      "[17/4000][300/600] Loss_D: 0.0003 Loss_G: 9.7369 D(x): 1.0000 D(G(z)): 0.0003 / 0.0002\n",
      "[17/4000][400/600] Loss_D: 0.0001 Loss_G: 10.2959 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[17/4000][500/600] Loss_D: 0.0041 Loss_G: 8.0294 D(x): 0.9979 D(G(z)): 0.0017 / 0.0011\n",
      "[18/4000][0/600] Loss_D: 0.0004 Loss_G: 11.8662 D(x): 1.0000 D(G(z)): 0.0003 / 0.0001\n",
      "[18/4000][100/600] Loss_D: 0.0008 Loss_G: 9.1134 D(x): 1.0000 D(G(z)): 0.0008 / 0.0003\n",
      "[18/4000][200/600] Loss_D: 0.0005 Loss_G: 9.1882 D(x): 1.0000 D(G(z)): 0.0005 / 0.0003\n",
      "[18/4000][300/600] Loss_D: 0.0237 Loss_G: 6.4524 D(x): 0.9881 D(G(z)): 0.0021 / 0.0029\n",
      "[18/4000][400/600] Loss_D: 0.0000 Loss_G: 10.4207 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[18/4000][500/600] Loss_D: 0.0002 Loss_G: 9.9491 D(x): 1.0000 D(G(z)): 0.0002 / 0.0001\n",
      "[19/4000][0/600] Loss_D: 0.0001 Loss_G: 10.3360 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[19/4000][100/600] Loss_D: 0.0000 Loss_G: 10.7868 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[19/4000][200/600] Loss_D: 0.0003 Loss_G: 8.3704 D(x): 1.0000 D(G(z)): 0.0003 / 0.0003\n",
      "[19/4000][300/600] Loss_D: 0.0000 Loss_G: 14.6361 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[19/4000][400/600] Loss_D: 0.0000 Loss_G: 10.7809 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[19/4000][500/600] Loss_D: 0.0001 Loss_G: 9.5596 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[20/4000][0/600] Loss_D: 0.0009 Loss_G: 9.2467 D(x): 0.9994 D(G(z)): 0.0002 / 0.0002\n",
      "[20/4000][100/600] Loss_D: 0.0004 Loss_G: 8.6426 D(x): 1.0000 D(G(z)): 0.0004 / 0.0003\n",
      "[20/4000][200/600] Loss_D: 0.0001 Loss_G: 10.1458 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[20/4000][300/600] Loss_D: 0.0002 Loss_G: 9.2968 D(x): 1.0000 D(G(z)): 0.0002 / 0.0002\n",
      "[20/4000][400/600] Loss_D: 0.0000 Loss_G: 11.1382 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[20/4000][500/600] Loss_D: 0.0000 Loss_G: 10.1853 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[21/4000][0/600] Loss_D: 0.0000 Loss_G: 16.9898 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[21/4000][100/600] Loss_D: 0.0000 Loss_G: 13.7650 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[21/4000][200/600] Loss_D: 0.0001 Loss_G: 12.4018 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[21/4000][300/600] Loss_D: 0.0000 Loss_G: 20.8501 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[21/4000][400/600] Loss_D: 0.0000 Loss_G: 23.9255 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[21/4000][500/600] Loss_D: 0.0000 Loss_G: 14.2179 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[22/4000][0/600] Loss_D: 0.0000 Loss_G: 12.9464 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[22/4000][100/600] Loss_D: 0.0003 Loss_G: 13.3762 D(x): 0.9997 D(G(z)): 0.0000 / 0.0000\n",
      "[22/4000][200/600] Loss_D: 0.0000 Loss_G: 12.7037 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[22/4000][300/600] Loss_D: 0.0000 Loss_G: 16.6426 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[22/4000][400/600] Loss_D: 0.0001 Loss_G: 10.5659 D(x): 1.0000 D(G(z)): 0.0001 / 0.0000\n",
      "[22/4000][500/600] Loss_D: 0.0000 Loss_G: 12.8432 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[23/4000][0/600] Loss_D: 0.0001 Loss_G: 11.1291 D(x): 1.0000 D(G(z)): 0.0001 / 0.0000\n",
      "[23/4000][100/600] Loss_D: 0.0001 Loss_G: 12.6549 D(x): 1.0000 D(G(z)): 0.0001 / 0.0000\n",
      "[23/4000][200/600] Loss_D: 0.0002 Loss_G: 12.4237 D(x): 1.0000 D(G(z)): 0.0002 / 0.0000\n",
      "[23/4000][300/600] Loss_D: 0.0001 Loss_G: 12.5987 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[23/4000][400/600] Loss_D: 0.0000 Loss_G: 13.7597 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[23/4000][500/600] Loss_D: 0.0004 Loss_G: 9.3521 D(x): 1.0000 D(G(z)): 0.0004 / 0.0003\n",
      "[24/4000][0/600] Loss_D: 0.0000 Loss_G: 15.1716 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[24/4000][100/600] Loss_D: 0.0000 Loss_G: 14.3250 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[24/4000][200/600] Loss_D: 0.0006 Loss_G: 11.6737 D(x): 0.9994 D(G(z)): 0.0000 / 0.0000\n",
      "[24/4000][300/600] Loss_D: 0.0000 Loss_G: 17.0129 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[24/4000][400/600] Loss_D: 0.0000 Loss_G: 12.9673 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[24/4000][500/600] Loss_D: 0.0000 Loss_G: 10.6216 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[25/4000][0/600] Loss_D: 0.0000 Loss_G: 12.4660 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[25/4000][100/600] Loss_D: 0.0000 Loss_G: 10.8966 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[25/4000][200/600] Loss_D: 0.0000 Loss_G: 11.2991 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[25/4000][300/600] Loss_D: 0.0001 Loss_G: 27.3804 D(x): 0.9999 D(G(z)): 0.0000 / 0.0000\n",
      "[25/4000][400/600] Loss_D: 0.0000 Loss_G: 24.6402 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[25/4000][500/600] Loss_D: 0.0003 Loss_G: 10.5355 D(x): 1.0000 D(G(z)): 0.0003 / 0.0002\n",
      "[26/4000][0/600] Loss_D: 0.0000 Loss_G: 13.4039 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[26/4000][100/600] Loss_D: 0.0006 Loss_G: 10.4117 D(x): 1.0000 D(G(z)): 0.0006 / 0.0002\n",
      "[26/4000][200/600] Loss_D: 0.0001 Loss_G: 11.0890 D(x): 1.0000 D(G(z)): 0.0001 / 0.0000\n",
      "[26/4000][300/600] Loss_D: 0.0000 Loss_G: 14.1428 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[26/4000][400/600] Loss_D: 0.0000 Loss_G: 12.7146 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[26/4000][500/600] Loss_D: 0.0000 Loss_G: 11.7097 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[27/4000][0/600] Loss_D: 0.0000 Loss_G: 12.2979 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[27/4000][100/600] Loss_D: 0.0000 Loss_G: 11.8428 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[27/4000][200/600] Loss_D: 0.0000 Loss_G: 12.4924 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[27/4000][300/600] Loss_D: 0.0000 Loss_G: 15.4330 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[27/4000][400/600] Loss_D: 0.0000 Loss_G: 21.4762 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[27/4000][500/600] Loss_D: 0.0000 Loss_G: 11.2736 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[28/4000][0/600] Loss_D: 0.0003 Loss_G: 12.4605 D(x): 1.0000 D(G(z)): 0.0003 / 0.0000\n",
      "[28/4000][100/600] Loss_D: 0.0000 Loss_G: 18.0769 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[28/4000][200/600] Loss_D: 0.0000 Loss_G: 11.5384 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[28/4000][300/600] Loss_D: 0.0000 Loss_G: 12.3727 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[28/4000][400/600] Loss_D: 0.0000 Loss_G: 11.7965 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[28/4000][500/600] Loss_D: 0.0000 Loss_G: 12.5763 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[29/4000][0/600] Loss_D: 0.0000 Loss_G: 12.1662 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[29/4000][100/600] Loss_D: 0.0000 Loss_G: 27.6310 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[29/4000][200/600] Loss_D: 0.0000 Loss_G: 20.2965 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[29/4000][300/600] Loss_D: 0.0002 Loss_G: 9.8546 D(x): 1.0000 D(G(z)): 0.0002 / 0.0001\n",
      "[29/4000][400/600] Loss_D: 0.0001 Loss_G: 10.0839 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[29/4000][500/600] Loss_D: 0.0000 Loss_G: 13.5178 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[30/4000][0/600] Loss_D: 0.0000 Loss_G: 11.9531 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[30/4000][100/600] Loss_D: 0.0000 Loss_G: 10.9716 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[30/4000][200/600] Loss_D: 0.0000 Loss_G: 11.2880 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[30/4000][300/600] Loss_D: 0.0001 Loss_G: 9.5145 D(x): 1.0000 D(G(z)): 0.0001 / 0.0002\n",
      "[30/4000][400/600] Loss_D: 0.0000 Loss_G: 11.8010 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[30/4000][500/600] Loss_D: 0.0000 Loss_G: 13.8753 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[31/4000][0/600] Loss_D: 0.0000 Loss_G: 12.8222 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[31/4000][100/600] Loss_D: 0.0001 Loss_G: 11.7067 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[31/4000][200/600] Loss_D: 0.0000 Loss_G: 13.9095 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[31/4000][300/600] Loss_D: 0.0000 Loss_G: 12.7524 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/4000][400/600] Loss_D: 0.0000 Loss_G: 13.3206 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[31/4000][500/600] Loss_D: 0.0001 Loss_G: 10.8222 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[32/4000][0/600] Loss_D: 0.0000 Loss_G: 15.3445 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[32/4000][100/600] Loss_D: 0.0000 Loss_G: 13.4979 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[32/4000][200/600] Loss_D: 0.0000 Loss_G: 21.0071 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[32/4000][300/600] Loss_D: 0.0001 Loss_G: 10.7708 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[32/4000][400/600] Loss_D: 0.0000 Loss_G: 12.5390 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b08d64d40419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0merrG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0merrG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mD_G_z2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moptimizerG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[1;32m    145\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real (data)\n",
    "        net_D.zero_grad()\n",
    "        real, _ = data\n",
    "        input.data.resize_(real.size()).copy_(real)\n",
    "        label.data.resize_(bs).fill_(real_label)\n",
    "\n",
    "        output = net_D(input)\n",
    "        errD_real = criteion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        #train with fake (generated)\n",
    "        noise.data.resize_(bs, 100, 1, 1)\n",
    "        noise.data.normal_(0, 1)\n",
    "        fake = net_G(noise)\n",
    "        label.data.fill_(fake_label)\n",
    "        output = net_D(fake.detach())\n",
    "        errD_fake = criteion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        net_G.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = net_D(fake)\n",
    "        errG = criteion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.data.mean()\n",
    "        optimizerG.step()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "                 % (epoch, niter, i, len(dataloader),\n",
    "                   errD.data[0], errG.data[0],  D_x, D_G_z1, D_G_z2))\n",
    "    if epoch % 10 == 0:\n",
    "        fake = net_G(fixed_noise)\n",
    "        vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png'\n",
    "                              % ('results', epoch),normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = net_G(fixed_noise)\n",
    "vutils.save_image(fake.data[:64], '%s/fake_samples.png' % 'results' ,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fea82c9b0b8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztfXuwHUXV72/tR85JTk7gHPIgJkGS4lWAFg/l1lVLP0XF\nZ6FyVSwe4qNiKVKf+KpQVvngL5SCa5UUX4H1IUhxpcRPSlBBBT5fpV4TrgEBCYnBkJwkBCQPcpLz\n2Hv3/ePstc+a3j0zPTPdc/Y+9q9qambP7u5fr9U9a7p7unuRUgoBAQEBjMpcZyAgIKC3EIxCQEBA\nBMEoBAQERBCMQkBAQATBKAQEBEQQjEJAQEAE3owCEb2DiLYQ0TYi2uCLJyAgwC3IxzwFIqoCeAbA\n2wDsArARwEeUUk85JwsICHAKXy2F8wBsU0ptV0pNAbgbwIWeuAICAhyi5indVQB2it+7APyPuMBE\nFKZVBgT4x4tKqWVpgXwZhVQQ0XoA6+eKPyDgXxA7bAL5MgpjANaI36vb9zpQSt0K4FYgtBQCAnoJ\nvsYUNgI4mYjWEtECABcDuM8TV0BAgEN4aSkopRpE9FkAvwBQBXCbUupJH1wBAQFu4eWTZOZMOOo+\ntFotVCoVKKVARC6SNKJaraLRaICIOpy+wBxlcAHo6K4MLuaYb1xl6ZCI0Gw2s8j1qFLqNWmB5myg\n0RWUUhEj4NMgtFotADOFoZTyWuiBqzj0F958rBuAe7n62iiwMkyFD8CpomQrRDdCZXFxi6FfuQB0\nuBiy/FxzlVU3AJRWNySXhEuuvlv7wMLrFcvHG4AtsixoIjIWShlcrmQsk6vM8pqruiG5fNSNJLl8\ndP/7yii0Wq0uaywRZz3zcvHZRvllcJkqRx4uOU6hp6W/5YpycVPat1xcL9Jaj3G/s3LZ6NAVV5Jc\npvBF0VdGQVp9k2FwbaWlNdb7h5LLFWfc4JQcPHXBJdPSuWTLwQWX1KGenkmHRThl3UjiYuTlkq0p\nE5esl/0kVyfNQrFLxL59+yK/45qELirzSSedBCC9n8ZcRZqng4ODnWvTQ+qSCwCazWaHKymtolw3\n3nhjJx1OyySblCsv51vf+tauNOO4uFXGv/Og0WikygV0d8+ygsuKkaZD+bsQZPNkrg4AKun44Q9/\nqBgzWVaJ4WUYm7B8PPXUU+rpp58uheu+++5TV199dSlcl112mVq8eHEpXADU6tWrjVytVss5F8fx\nzXX//ferU045pRSu17/+9arZbPrg2qQsnse+mKcg82jzdrMNbwL3E/NwZe2+FOEqU66sXLZx5ZcP\niSx8ZXIV0WEWriwtmoxcVvMU+qb7AMDYp5Jw0XUw9QfjwsmCSwufxqWnlcaVFUXkygMuq6S0XI0B\nybecT66ydKin7bvO6+h5ozAxMWEdttP8ydmn2rEjfhHZ5s2bI7/1CSRZ8dWvfjXyW6bzwgsvOOUa\nGBiI/U+vvEW5br75Zuv4/HVChs3CW6/XreOY6kYWrpGREeuwJh1mbZHYoqhcJvT05CW2gCw0EeGZ\nZ55JjJP3jWCK8+c//7lzfdZZZ0X+4/zkeSOYuK644orO9bJl0SXvrrlqtdliN319yPv2kZ/ouGKe\nccYZiXF4im5WY65z2cxHcFk3li5dGhu+iA5NcZ5//vnEOM7nRtgMPPg+kDKAJMEDLe1xiMR4GzZs\nyDxYpQMWgzsyX/3ExWdXXK1Wq6usOP7SpUtTuc4++2wnXDb6sOUpW4cmcPy77rorNV6z2UxK32qg\ncc4NgrI0ClwJ9IoxMTHhpeD1gpT3RkZGvHNxmq985StL47rggguccZkeUiJSjUajK56pbLNymeKb\nHhDfOvzRj37kVId6/FNOOcVoZCy5rIxCT3cfZBPM1DRstVoYHByMTPjh8HzOwxXHx03darXa4c8D\nGy7uLkiurDJl4VKi+e5KLh2mFX0uyiuubvjgiuPTdZinrHQuE8/TTz/tTK449PRAY9Lovv6JSZ6T\nJpTEIUmhetr656Iin+ySuIBZHTQaDVQqFW9yyfNLL72USy45Dd30H1dmnTNPeSUZrrLrhnyQ+bx/\n//7cOkz6zzS7VSmVq27EoaeNQqVS6bKc8o0pB5g4XF7FmAaHWq1WpKLX63U0m81SuGq1Gg4fPtyR\necGCBYW4JJRSkYezUqngl7/8ZYcraRAtCbJiysFRubZD/l9Eh3rdYFl0A+CybkhIHXKL7stf/nJH\n5tHRUWdy6TqUrRKWy1UrAcCsIufyQMZ+FjA7IFer1SL3ix7cF5Z9Ypl2q9VSGzduLI3r4x//uFMu\nButV/l+pVJxzSblarZYiIqflpYO5pIwuuUw6lDL61mFBuebPjMaAgAAnmH8zGgMCAvwjGIWAgIAI\nglEICAiIIBiFgICACIJRCAgIiCAYhYCAgAiCUQgICIggGIWAgIAI5pVR4IlYLnYOSoOcdjqfuOQ0\n4bK4ypQrlFc6enqVpA2k4pUqx12X/D0f3KvpXEoV28nZlgtAaVxlyuW7vHRZXMvV1y0FVry+maZc\nQOKSq1qtdinfF5dcGONbLhOXWJfiFGkLmXxxSR32u1xxC7RccfWdUdCX3gJRd122W3Nl4ZKc+tJb\nVxa6TLlkk1Ma1DJdnvl2vRfHVUZ5ueSRHDqXr1ZPXxkFLojp6elEhcgVX0W5TM1Aye2iT8dce/bs\niZVLX8mWF7JvHbdZiCm8Cy49LddcvGzZtFGJSy59GXNc681F3dANeFpaLgxtXxkFFrharSa6V3MN\nuQMS58Nlf3FychIAsGLFili5ADdvH/mwmPqiPt5wsk+fxpW3/OK4TC0EV4NzcQbBtTs8hikNk6Eo\nytVXRqHRaHSuk9yrMfIqZ8mSJZHfScZmfHy8EBcws4399PR0h8sEWQHzcl1yySVdafrC2rVrAUQf\nyiT3akXzxK4ATF08HXGtBxsMDw93rvnlEOfKTYbLw6UbnLgug812cZlgs+mC7wMJG0OsXbtW1et1\npdTsphJqJlLqhhi2YeVRqVRiNz1J48qzmYfkyiJXFq7JyUnVaDQUw6cOP/CBD6jbb7/dyJWU5zxc\nzWZTffjDH7bmqtVqubmq1apatmxZKXKtWLEidkOcpHQswsyfTVbk554kK6jvzcdxskBa56S3jb7n\nYJ6Bn+np6U63xIZLGNFC+wymjccUffMU4crKVyaXHIfJWg9Vxi6nJ7nmzyYr8jNZ0ic5+ZAWRRYu\nmwEgE6RTFhsurgBFm4dJeU0aOPtX55LjFVnrYZEyS5PL9Yu9kFEgon8Q0V+JaDMRbWrfGyWiXxHR\n1vbZ3t+WAYsWLWKurv+4H84wTYzJArnZps532mmndXEdOXKk8OCmSS7TJKmDBw92beltiyNHjsT+\n9+yzz3ZxFTE8v/nNb6zD6uWlX6dB9u9tuHS5snCdfvrp1nGKTtDKYry4LuSVKzbRvAeAfwBYqt37\nFoAN7esNAL5pkU5sH0nH4OBgap9KbnoZF1Y/5CaZfCxYsCAxvOTK0seX/UXZb7SVKwuXCY8//rhV\nv9Qmb2lcn/rUp0rjohSvYXm5ZN1grF692rpuFJXLdszCQi7/HqJgNgpbAKxsX68EsMUincwKSlNU\nq9VSU1NTmQredABQV199dSrXsmXLMleyvHItX768UCWTFSktXlEDxBxpcrnkspErKUxaecm6kVTH\nOOwtt9ziRK7TTjutqA5LMQrPAtgM4FEA69v3Doj/Sf5OSCdVQaY3pFTYunXrugrRtiA4jskgyP9N\nbsiyvrlNBW+Si+9Vq1WnXLpe5L2TTjrJeN8VlywX+VZ3wSX1Qu1t5DlN6aquKJepDPbu3WssFx/l\nxenGxUtJvxS3cW9QSo0R0XIAvyKip+WfSnWadF0govUA1iclbpqZZgojJ/zk/ZZvM0ipT5rKO3Al\n5VKqu7+plOpyDeaCKy1M3rEYWy7u0/vgkjrUHc7wFx5fci1fvry08pJfNorqMA6FBhqVUmPt8z4A\n9wI4D8DzRLQSANrnfTFxb1VKvUYlfCJJUqx8qOT5wQcfzOVCK4lLTmuV5y1btnjj0uU6/fTTS3Mb\nxxWuyKdI03+6MfTBNTIygkajEeFqNpudcx4u/vIT95/JHZ4vN3+m2ZKA27UQuVsKRDQEoKKUerl9\n/XYA1wK4D8BHAVzXPv8kL4e0utIq8gHMvL23bt2Kk046qdByVZ1Lqe7PTvJt4JJLysUgIkxPT6Ne\nrxfiMr1N9OtarYZDhw5h8eLFxpZLVq648uL7preda7larRZqtVrEFV9eLlN5yboh64Tecs0Kk1x6\nnZStrSJyxaFI92EFgHvbGaoB+D9KqQeJaCOAHxLRJwDsAPCh4tmMKkl/KNetW4eFCxc6W48Qx8XK\nv+uuu7xzAbCa2JSVS06+4TcPAAwNDWH37t3OKpjk0ideAcmLv4pw6S0EvexccDFMXc7Nmzc730dB\ndrv0vLg2CAD6Y0ZjQECAE8yfGY0BAQHlIRiFgICACIJRCAgIiCAYhYCAgAiCUQgICIggGIWAgIAI\nglEICAiIIBiFgICACOaNUZCzy1zu5hMHnvTlm0vOdS9DrvmoQ8kx3+TywTWv3Mbx7/noyq0MLvl7\nvsglpwH7mhYMzC62Yp5+1mFftxTi5rUnrWpzwSVX9pXJpa8fcM0F+HW9B5Tvyk2HDx0CiLgULEMu\nn3Wj74yCab8Eoqi7LldvA8klC9y3G7I4LldI0qGsaC5ks+VyAd9LiiXKlCuNyzX6yijIfmGcwqXF\nLKIwLtg4Ln2JaxEuueTWpiIV5QKSXe/J5c4uuKR8cXzynJdLX1qcxOFCLu4y+JRLr4d6WqYNeoqi\nr4yChKkfpe+4UwSyJWDqi5qW6hZFHJePvmmS6z3XiNORfKsWfYBk68ZkzEz7N+TlknXDZBBcyqXX\nwySj4MIIAX1kFKSPBCDZvZqLCsbx0wanig5evfGNb+ykI7njuIqCdyEC/Lrek2AdxblX05vFWSG3\nvvfNpaeR5DZO1sMidUTWjSTXe/qYRl70vFE4+eSTcd5550V8LSYJzYrL0+d66qmncMUVV3SaarZc\nfJ2F6/Dhw5iYmMBvfvObxMKWXLzpSlauRYsWoVqtQqmZ/Qp96nDZsmUYHh7uxJFcpreq5Mrb6mJD\nZ8vF11m4PvnJT+LEE0/stK7SuGSYrDp89NFH8Za3vMVo4FzLZUJfbLIiP8EkVWa5zZdIO1NeZL/e\npoUwV1xZK5qsTLYu6hi+5DJxZeWzzacLriL1MA9X3rqREGf+bLIim/NJn8lcuI2zbTonDTCVwZXV\nmEuusnRYRnkxjw1X4TeoaM1klatIefmuhzp63ih85CMfAWC2fM8991zkt7TkQPaCeP/73x/7X5qL\nuqw4fPhw7H933nmnU64FCxbExp+amkrkyqrDlStXdq7T8mviyiKj7E6l8fHXCRkmC9eaNWus45nk\nyjKA++Y3v9k6rKluFB1T6OkZjaYm0Zve9KbO7xNOOKHrf7acWSuYqfKfdNJJnet6vW7kyvP2McXZ\nsWNH5/qyyy7zxkVEGBgY6Pxmg6FzudLhsmXLYsNLLv6dlyutSa9zZYFJrrVr11pzFdXhqaeemsrl\ndBhA/yY9FwfM3myUCa0M7tUOHToUG8aGS81krnNOipeUnyxcaXK54Mqiw127dpXGdfDgQWuuVoLr\nvS9+8YupeaxUKqXJZfIsNkf10L/bOFeHjYJaMa7c+N7w8LDxft7C0OPLwrnooouM931wHXPMMc64\nTHqR/EuXLu166FzKJflHRkaccZnkGhkZKeJezVouIork/33ve5/XuiG5zj///KxcpbiN8wqbZpEv\nd12mJh+HSfoU5Zorr/t5E5eJhzlMOszKmSaXbFa75DLJ9c9//rNLLg7vUi6uDywXj3PkXfdgq0NZ\nD/PWjTj09EBjkmLlFFpgVjHj4+OluVfjz0ZZB3aycOlrIvJ8Hkz7T+f6y1/+4lyH+jRdPh86dMiL\n6z2Te7WjR49azQnRkVZeUi7O14EDB7zUQ5MO87rDi0NPGwVWqm6NZYWo1+sd34GtVgvDw8O5uExK\nVUpFHpxarYZNmzZ1uPRZllm5ZAVgubgJNzAw0Cls2WLICrmiTueSYV5++eXOm/Xcc891LhdfVyqV\nzrqLVquFY4891plcrDvmkl8llFJYtGiRM7m4bvB5wYIFuP/++ztyjY6OFuKSkPWQWyMvvPBCJ095\n62EsbPoYvg+k9LO4zyj7jrKv1Wq11Mc//vFMfbc0LtlHk321VqulRkdHnXOxPDrX9u3bnXIl6XBo\naMgrl7w+4YQTvJWX7HcrpdT+/ftLk2vJkiVOuLhO6PVQci1evDhrulZjCn0xozEgIMAJ5s+MxoCA\ngPIQjEJAQEAEwSgEBAREEIxCQEBABMEoBAQERBCMQkBAQATBKAQEBEQQjEJAQEAE88oo6OshfEKf\n6z5fuMrUYeAqBt530zVXqlEgotuIaB8RPSHujRLRr4hoa/s8Iv67hoi2EdEWIrrAWU5jINcM8G+f\n7rrk+gSfXM1mMzL1tCy5iq61yMLFv8uSa77psNFodH6X7TbudgDv0O5tAPCwUupkAA+3f4OITgdw\nMYAz2nFuJqKqs9xq4EVJpiXNrq00K15y8bXrqeJyCa4ul2surrymRTg+psCXpUPJBSDysPrmYpSh\nQyDeJ0Tu9NMCKKV+C+Al7faFAO5oX98B4H3i/t1KqUml1LMAtgE4z0lO2zAt9+XlsLKiuVhGqi9b\nBspx5Wbicrk0lvMuZXCZvg2XDx0myeVatiQun3VDcvWa27gVSqk97eu9AFa0r1cB2CnC7WrfcwLZ\nV0sqZG0FphOuuLRMlSMr+KGXTkoBdPZS1DfTKMrVWQ0Xs+lK0u88XGXoUHbrTFw6R14u+VaO49JR\nRj10wcUo3BHhZZ1Z4xHReiLaRESb8vCa+lGuLae0/HFcLt4MY2NjUEpheno68rBOTk528sFnF/Lp\nTWoJlzqULRxT18e0EUqRh1XKZeLSu5R5uGSTPYnLpXFN6ma55gLyG4XniWglALTP+9r3xwCsEeFW\nt+91QSl1q1LqNTZLOYFuByY+XZ7xLs5Jb1TmSvrfFuvWrQMAPP74416a8AzpMg6I32XYhfG58sor\nAczqMMm9muTMI/8jjzwS4YrbXUkahrxcumGJ49J1mIeLW4rSEPniikA2heIOACcCeEL8vh7Ahvb1\nBgDfal+fAeAxAAMA1gLYDqBqkX7sxhDValVVKhWllN0OunxwC0a0ZFKPdevWqZtuukkxbOPn4ZJx\nTRusuOQaGBhQhw8fLkWuarWqXv3qVxu5ksotrw4XL15cCle1WlUTExOlcC1fvlx94Qtf8MHlZjdn\nAD8AsAfANGbGCD4B4DjMfHXYCuAhAKMi/FcA/B3AFgDvtMpEipLk7jpp4VgpUqFZDn23G99cNnLJ\nws7LZRu3TC6TDrPylcXFL6ay5LKth6bySogzf3ZeUrPGA0C6L8R2mpGzLZiHz2lcMv28XDbx169f\nj1tuuaUwl1LpXzKy5Csufpby0tPPwpeFy1TX83Jl1WEeLtu4Gbisdl7q6S3eAWBoaAiAuZ+7d+9e\nHH/88Z3fPJjFM72yGrx777039r8zzzwTTzzRmb8VMT6uDSs/uIwDBw5gyZIlubn0sYQ0bqVU7gHH\nt7/97QDs9GLSYZYH57Of/WwmLl2uLFzsNtD2C0ARrt/97nfWYYvKZUJPGwXTm1i6PJMGgVGtVp24\nPCMifOxjH+v8lgaB/+dR9axIs+x6vo855pjcBsEk17e//e3EOHkNgokraQflIjo0faIbGRlJiDE7\n0Ji3bshWlu7v08TlQocAsHPnTkPIGRTRYWIm5vqARb9KKdW1c25cPA77+9//PlffVPIBUI1GIzXe\n+Ph4IS6lZvuGafFsBlpt5Dr22GNT42XZCTmJK8l1GmPHjh3WXEl1wyaP9Xo9t1ySq1qtOpUrqW6k\n1XmllDp69GhS+v0/piDzxteyz8hCVCoVLFy4EEePHgWQz0lLGhdbYr3PymGLtEpYBlOaExMTGBwc\ndMKlDOMJvuQy6fDll1/G0NBQKVwAsG/fPixfvjxyz0XdMMUfHx/vdHX1eEXqhh6/YHn1/5hCWpOZ\nHyY5kck0JTQrV5xiy3KvJsPwf3mbh3nk4vCudcgGwSVXXLxGo4FarRZZs+KrbjAHnyuVSmccp2jd\nMEFOnJMcrl7wPb10Wp8FZ7KYekH/+te/duKGTPLqHHqeXLkGkxVCP/MU6KyDSEnGJE4urnB5dBgn\nGz8wZXGxQWCOTtPYAZdeN3S55IC3a9d7Jh3K9T8u0NMtBflGjntjVioVHDlyBIsWLSq0hFTnMg3e\n8L2iMxl1C2+61rsuruSS17Ip7EKutPLi+2Vx8dvbNZdeN1zKpZeRSS7m0lsMrtDTLQUJ2VTkQuLz\n4OAgXve61zmzlElcALB7925nBSE/F3KazMX/+ViXr8/jkJXaBaSRM+X/yJEjXrmICAsXLnQul4Tk\nkl0UF1x6N8KkwwMHDniRq6cHGgMCApwiuI0LCAjIjmAUAgICIghGISAgIIJgFAICAiIIRiEgICCC\nYBQCAgIiCEYhICAggmAUAgICIghGISAgIIKeXvtgA9PuPT7ddUmuPAuU8nAB3eshXEIuFmKUIZfv\n8ipTrrnQoUTZbuN6FnJZrL6U1PX07bniYqQtFc6LOOPmgwvodhsH+HGHB5j3UfQlV5lcvKaDeQG3\nrhL7ziiY9u3nBSmuV4zpy3t1LpeI47JZX1+Ei+Gr1WPaw0AvL9cLo8qQay51ODk56U2HQJ8ZBbmH\nQtLD4mLTCX2tug7TWyEv+E2ZtsLOlVympq7OEfc7C7i8uBLHvcl8yJUmR79wsc6+9KUvRXRo2oGs\nKBejr1ZJyocmro8tK14RC2qzfbuuu7xcNukU3U5+LrgmJydRr9cTxw9MexDk4TM9iHFcEr3OdfDg\nQQwPD0fumbgkR8L40/xaJSm370oadJOKz2vwzj///Ng0XWPnzp0RSx/H5aIbYdo0xheX5OPySnN5\nlrf7Z5LLl3s1k+s9n67c7r77bkxOTmLnzp2prvcANwPSffP1gQsjrcLKlkTWXXDkHvq2XHl33Bkc\nHMRPf/pTrF692rtcAPDiiy9G3sS+uOr1OhqNhtEfgWkHqaJyTU9PG+UypVOEq1qt4vDhw8a64ZqL\nIbsKsuvsWoc6+qL7IJtiScLqe9ilhTfBNq6pP5l1ANKWa67lyluZ07pvJrmyvOn0cYqscqXFMaVR\nFhd3vYB0D1umfRuLdB96vqVg+tpggzzWsqiBzBLfqfOOFOQ1VHlQVK4sZZaFq8yydalD33XehJ4f\nU5C7GPMIPePGG2/sCt9sNnN/ypucnIz8lvHHxsa6/itSCLt27YqklVbBi+z9J9OW4xcmyO5QHtRq\ntUgLIYtceQy/vM4qV14u02+XXDyXw1TndRw9ehTj4+OR8EUNQ0+3FEyKlb8///nPd8Vx5TYOALZt\n29a5XrVqVeS/vIbHxEVE+OAHPxgbXo5duOC69NJLE+O4dHlm6zauaHkRER555JHEOC7leuyxx7xw\npdV5HYsWLYro0AnkN9e5OoDsrsGmpqaMcWZEmgn7ile8IjaMKY4J/F9avFYBV25Srs985jOp8Z58\n8slCctnklbFhwwYnXEmcHG737t2lyfW3v/3NCVeS+znG888/b82l1/msOrz99tuT0rdyGzfnBkEl\nGAVdMbpSTPekYm0LIq7gTf8DUNdcc43xfh6uLHK54NLjHzlyRP3sZz9zzsV8ceWyatUqZ+UVF9/k\nB9OFXKb4LsuL5YmrG5zm2WefnVpntMPKKPR098FmFNzkhkzNGpvcXElhdJdnWSG54pqGZblyO3To\nEN797nd3uEZGRvDSSy8V5jLxye6Cbzd/0hlMpVLB4OBgx9eo67phcsziom7wb/3/OB26Qk8PNCb1\nk+R3W2C2ELZv357LbVxSIeoPpP5FJM8nO8knr3V55Dluokwal4TOtXz58gjH/v37c3Ol6VD/tg8A\n11xzjRM3f/p/+me6iYmJjkH3zcXnvHWDocfVp/dz2IULF+aSKxY2zQnfB1KaVLKfxc0k2Vyy6XPZ\nHnFotVqqXq+rhx9+uBOuKJetXD645FlyKKVUe96IEy5dNiJShw8fdlZecXLpunMtVxqXS7l0HQJQ\n3/nOd/LosP/HFKSCZCHoymi1Wuqiiy4qXBBcoLJA9EJWSqkbbrjBCVeaXPK+C7lkBZNcIyMjTrni\nDJy8rlarXuVSSqlKpVKKDmU9canDqampSPpSh41GI0+6VkahL2Y0At0OQ9vxvORH51LK3wYncyGX\nLPMydMjwrcMy5SqDq9FoRLxnA4V16GZBFBHdRkT7iOgJce/rRDRGRJvbx7vEf9cQ0TYi2kJEF+TP\nv5ZR4eg1T1+tCJevymziKkMu5ilLh077uwlcZcpVBletVutw+tahhA3L7QDeYbj/v5VSZ7WPnwMA\nEZ0O4GIAZ7Tj3ExEVVeZDQgI8I9Uo6CU+i2AlyzTuxDA3UqpSaXUswC2ATivQP4CAgJKRpH2yFVE\n9Hi7ezHSvrcKwE4RZlf7XkBAQJ8gr1H4DwDrAJwFYA+AG7ImQETriWgTEW3KmYeAgAAPyGUUlFLP\nK6WaSqkWgO9itoswBmCNCLq6fc+Uxq1KqdfYjIYGBASUh1xGgYhWip/vB8BfJu4DcDERDRDRWgAn\nA/hzsSwGBASUidS1D0T0AwD/BmApEe0C8DUA/0ZEZ2FmQsQ/AHwKAJRSTxLRDwE8BaAB4EqlVNOU\nbkBAQG+ibyYvBQQEFMb82I4tDTzbSy4UKcttnG8ufcWdb7kkfHGZdsYqo7wYPmc6cvr9LldPr5JM\nA0851behSlpd6ZLL+Y43gqtanZnzVaZcgB83ZBK8vZ5vHQKIyMUQ6228cEm5inIlLav3KVffGQV9\n2TLgzw1ZGhf/9sHFZ99yMUxcLvjSuPi3C3B6OpfNXhlZYSNXUejylCEX0GdGgQviD3/4Q6JCTErM\nw8VvMROX3rQvygUAe/fuLY2Lm/Em6KvminARUcc3g0+5Iqv8LB4WFzqUdSSJIy9XrVZLlMtUfi6M\nRF8NNL7aa96VAAAUmUlEQVT88ssYGhrq/Db12WRBFHnb6X3EMrgYPrkajUYk/TjXe3pTOA/k+AHn\nXefT5QJ635Wb3qdP4ioiV6VS6fJIVVCu+eU2DgAeffRRq0GcohaaiDqFkbZsWhZ6Xhw9ehRKKUxO\nTnqVS4+b5HrPBdeRI0c6aSStNi1qEBqNRuR3HJfNmzYNCxcu7FwnyVXUIBBRqXJFoDcV5+JAwsYQ\n7VaEUmp2Aws1Eyl1QwzbsHxs375dfe5zn1OMtPiVSiU3l8ynb7mOOeYYNTAwUArXPffco5YuXWrk\nMm1Awput5OFas2aNajQaxvJK2uwkD9d73vMeddVVV5XC9eEPfziy0Q8RpXINDg7acM2fTVZkcy3J\nCrrYAMN2sxNl2cdL4+J4ZcjFyOqGLO+ehmlymXTI8WygN6/TuPRNX7JwAcXcF2bhOvbYY7F//36r\neEopDAwMdDkymtfdB9M3Wd9cZWCu5MrCxw9tHq4y5NL720ngt2BelFk3pEFgLFiwwBhWKYWpqSmn\n/D1vFPRvsrJwTAUlR9WzVoLLLrsswiXj6/07pVQh92pZ5Tpy5EhuudiLEL+VZfqmCsVy5fnkddxx\nx8XqUIdJh7b61POW9tDLL0lZuQDg/vvvj+g/zUjok89suer1ulGupAefWyaMoga5p2c0mgo5aeSc\nB2LyvK1MXG9729s617w1luRK+hyVlStNrkWLFjmRi4giX3D0N5CUK2tLwSQXe042oYgOTd2AAwcO\nJMZx5TaOiPDd7343NnwRHeoPPxHh4MGDiVymblEh2Aw8+D6QMEhjAiwGd1qtlnr00UetB3eSuPic\nFC/LLr4mmHZzjpPrkksuKY1r3759fafD1atXp8abmJgoTYdFuOQOzmeddVZqvGazmZR+/2/xHlcQ\n+v8A1Kmnntq5L7fFLlIY/B+P/nKa119/vTEPLrj0NFesWOFNLllxAajjjz/eG1e1Wo3I9cc//tGZ\nDk15rVQqXlzvmXTYbDY796RvyaI6NMWv1WqRB19+AbPg+tdwG8fNNJduyHQuvs9huCuRt8nWK3Jx\nerqLOh9cPCjIYXhtR54mts5lisuTtKRcHN61DmUTvqgO07q/U1NTES5+kPNwxebBSSqekCSkrgg+\nj46Oencbx4OOU1NTuWb85ZFr0aJFXlyeSQ7+vWvXLi86lA8XG4kXXnjBuMAnDbpcktv0WVXmwbXr\nPRNXs9nMpcNmsxlJP42Lj3q97mxVZk8bBdMIuFIqUpmJCGNjY503a9pgUx4uVvzChQvx0EMPdbgG\nBwcLcUmY5HrggQc6XBMTE7m45Oo9RktbAVmtVrF3797OG+iEE07IxZUmV6vVwsDAAF772td25Fqx\nYkUuLl0uTk9fl8D/cYvIFxe3Hvm/pAHWNC59sZiNXPrXsUKw6WP4PpDSz+LBFtnHkv2nLANULriW\nLVvmlEv2B8uQyzRI1mq11OLFi73qUPJSQb+OJh3K9JWanQnoSo9xOpTXDz74oFe5WHc55er/MQWG\n7EOx1ZRvPpebWUiuqampUrjk56sy5NJbCj65Go1GRzbpNco1l9QhgMjb1DWXrsN+l0tHX0xzDggI\ncIL5Mc05ICCgXASjEBAQEEEwCgEBAREEoxAQEBBBMAoBAQERBKMQEBAQQTAKAQEBEQSjEBAQEEFf\nzGhMglxRxhOx5oPbOJ7dmHenoCwwLZqab27jWJe+dTgf6kZftxR4ymnWrbmKcgHRBVSuueIqcJly\n6dO7XUF3G8d58MFlcofnQ4eSqwy5fNeNvjMKpnXqcjmsS4vJHLKg8+5dmIWL4evNlqRDfY69by6X\nMibp0IcxNXGVLZcP9JVRMC0fNcGkxCyQLQC9meaai+MmcelpF+EqS4eSo9FoRPZiNL29i3ANDg52\nGfC0hWUudCiX7JvSd1U3+Gwybi7rBqOvjAIQbd7qhW3a7CIP9Lel6WF16Ui0bC5Gkg5dvV15daR8\ncEwr/oqU28jISBenTEffnETPR1bwnh0rV65MHI+RcuXdpUvClF+XcnXSLBS7RFx99dUAZgs8yeUZ\nn/MqZ3p6OsIV90Z10XwzuQaL4ypasU477bTI7zS3cUUNA+uRuZLcxvE5q07XrFmDsbGxyL243ZXS\ntlWzxT//+c/Isuk0rqT6mgS9vOO6DK7k6sBm0wXfBxI2hlixYoX62te+phgzWVapG0pkCctHrVZT\nzz77bClcANSXvvSlUrjGxsbUM888Y81VqVRUpVLJxfW9731PjY6OKqXs3MaRcAuYlevmm2+O3aQm\nbgOSWq2Wu7w4XRu5ipQXEcW6jUtKxyLM/HIbZ7O5hKmZmMVq6m9jn1wArOO64LLVoTK0EOr1eqbt\nvuTYQVa50vInMTQ0hMOHD1vFU4ZuTBYuIOqxO6vrvbQ4pvza5NFUXglxrPZT6Pl5CnmbzKysLMji\nhqwoshjjooY7iw5NXHkNQhqKNnOlQZBpmmTgt2Be2L4sTLxFXhYuw9oi1XQR0Roi+m8ieoqIniSi\nf2/fHyWiXxHR1vZ5RMS5hoi2EdEWIrqgSAafeeaZyCCcLJzR0dGu8PxGzFPh2HW6icuEtBH8JEiv\nP2lccmuuPNi0aVMkruR67LHHusKbBiBtsWzZslguE4+UK+sDJB8I2fxNCi83VM3CxfMQ2Oik1Q25\n03cRuUy/JUzpex9TALASwDnt62EAzwA4HcC3AGxo398A4Jvt69MBPAZgAMBaAH8HUE3hiO2/cd+U\nzzfccENif4/PctNQm8PE9dGPfjSVS6II1ymnnOKFy4S77747Mbzepy3CVavVUvvArrg2bdqUGJ7H\nSVxwVatVK7my1kMTkrw+cdqWcvnxEAXgJwDeBmALgJVq1nBsaV9fA+AaEf4XAP5nSpqJDw9DDvLs\n3r07VbE7duzI/KCauIaGhlK5/vSnPznhsqkwZ5xxRqFKJo1nWrwsOwbHQVZen1wcf+/evaVxpemw\n1Wqpa6+91okObeKNj48nhXNvFACcCOA5AEsAHBD3iX8DuAnApeK//wTwv1LSTVWQ6cGJe5hsH7Ks\nXNPT07HxinDp8Q8ePKjuvPNO51zMx/+RtlX4m9/8Zm9crENOUz4oPnR44YUXluY2TvLLF0jRehiX\n1wJyud3inYgWA/gvAJ9TSh2S/RalFH9asgYRrQewPiVMaj8xzl1XVsgBqrg+Wb1e73BVKpXOwGRS\n/vJw7d+/H5dddlmHa8mSJZ0xiCJcOh/fZx2yB+q8c/bTvpfLiWe627giXCYd3nvvvZG64aq8THym\nCXUu6qEJ8suGPiPUFaxGk4iojhmDcJdS6sft288T0cr2/ysB7GvfHwOwRkRf3b4XgVLqVqXUa1TC\nJ5KkCiOn67bTmxUqp3s1TkM3RCYuDu+D64QTTohwHTp0qFMJXLqNk3kAZicb5XV5FldWplmSnK/9\n+/cX1qHpP52Tw5955plO3eHxQKmuy7Vr1zp3vRf3qRNwvBYirSmBma7B9wF8W7t/PaIDjd9qX5+B\n6EDjduQcaORD9sG5SSabZjb9O9vDlku0jpxxyTNzyLMPuZrNphoeHlZ79uzxokOdr1qtqg996EPe\nykvy6eWVNOhZVC4A6ujRo6XJlbNuuBlTAPCGdoKPA9jcPt4F4DgADwPYCuAhAKMizlcw89VhC4B3\nWnCkKiju4eTrycnJwgUhubgQJJfeB/fJNTIy4oUrSYff+MY3nHPJyit5K20X6j50yNB5fcgVp8+i\nhw5OX6lC7vDmz4xGYLbpJJtrPjfn0OcGOGuazSFXs9lEtVrF9PR0p0/vczOVsrjmqrwYvuWSz2hB\nuaxmNPaNUQgICCiM4DYuICAgO4JRCAgIiCAYhYCAgAiCUQgICIggGIWAgIAIglEICAiIIBiFgICA\nCIJRCAgIiKDnt2NLA88sk4tSfLs8k/A5m01fBTcf3OHpXE4X8vQQF9C/rvf6uqXA00D1Qs+7HDeN\ni12eAbPTTX1yAYgskW21ty9zzWXSoViX4hQ+3KvFPRBz5TaO4YvLt+u9vjMKckmxLPB+d3mmy8Xn\nMriAbh26QpoO+bdLDp0rbY+CPIjj8uG+sMx6CPSZUWAF6GvYGXpzu0hFkHsoxCncsNqzENfg4KDV\nbsQu5YpLywUXlxc3d+PKS+fMCtmykUaVIVsSrnSolCpFh8whzxIu6zyj74wCMFsJ9GajfOu5fDNw\nE1vCZR/ugQceADCzm3QSl6u3gXx7+nK9J+NzmklGoQhnWheBu2N62kXkS+qqmnRY1LgC5g1zTHW+\naLn1jVEYHh4GMFvgSQ9I2v9pGBwcjPxOc1HHnHlx1VVX4cc//jFuuummRC5TMzILLr300k78JB25\nMq779u2LcCUZ0rxLnnl5NoBELl3evHXkjjvuiHAluY3jc14uvTuX5nrP2bJxm00XfB9I2BhiYmJC\n7dmzRzHQ3oAiLjwVdEN25ZVXKqW6XZ6ZDt7mOw8XH1k36cjDtWjRInXbbbdZ67AI18aNG9Uxxxxj\n5DLJV6S8Fi9erF588UVrriJy1Wo1df7555fCtXHjRvXpT3/amos3rLHg8rPFu4/D5sGRCrIpAJvw\ncVxyZ52kcDpX1u3Zrr/+eqsdf3WuPDv82OrQJJcvLlN5ZeGrVqvW8VqtVmfHoryyZeEqIleWephR\nh253c54rJA30+eAqgpmysEOz2cTu3bsB+HdD5vozZhpXWeUlvVqnQc2+gHIhrw6LlJdNvCIyxaHn\nxxQeeeSRyG+phAMHDnT9V6RSXnvttZHPO7IijI+Pd4U3TTCyRbVaxerVqyO7Dct0Jaanp3H55Zfn\n/rwm3cbpXAsXLuwKX0SHvE08IymvpvLKwit9f+py6ZAj+Hm47rzzTmsuoNt9YRauK664IhLelotR\n1Cj3dEvBVKEuvPDCzvWxxx4b+a/IN2lTnMsvv7xzPTQ01MUjR5+zFISpEOVvfTBpwYIF+P73v49m\ns5lZNg7PeSSiSAU/evRoJHwRuUx50wdtTVx5ykt+DuQ8Pvzww4lx8s7D0LmICK961atSufK0Lkz5\nO+6442LDy/JyBps+hu8DFn04vb+U1NdiZOl7m2AzAMjhkvz96Yfsc+fhSvJjmCaXHMPYunVrarwn\nnniikA7LKi8p1znnnJMa76WXXspdXpLrF7/4RSrXPffcU0o9tNBh/w80xikHQGTQCIC67rrruuLZ\nFoTOpQ/+8YAW37vooou6KkxWLlnR9IKU+V+6dGlhrji5OE1TRSrKlSbXc8895628gJmvBY1GIzae\nS65zzz23NB3KNG+88cascvX/QKPetDTNC+AwtVotcr8Il87LfVduEg4MDAAwTz/NysW/TWHkRKai\nXEnxdNd7HNaXXEqpLq6sSOt2TE1NReRy6XpPx8aNG0vRod5trdfrAPLXjTj09EBjnJCm2VuNRqPz\nO89ccH1mmj7QIx+syclJADMzEF27BtPl4gJnnrzu1Uz6kFOede60yUZJeY/7T5Ybc+7evbtQeZk4\n+eGUcrHrvcHBwdw6tOXis0sdyoFSTpvr/Pj4eC6uOPS0UTBVFqVUZ8Ct1WpheHgY1113Xey0XVvw\nAycLpaWtSlyyZAk2bdrUqQSLFy92KpesWESEn//857kHrBhSLvmWkWnKadRFdBgnlzQE9Xod55xz\nTicfq1atKiSX5JVyybc2y7VgwYKOQffNVVSHsh7qdX5gYAA33HBDJx8829cZbPoYvg+k9LO4Hyf7\nU7L/1Gq11Otf//pMfTcbLtMAT6vVUu9973udcTWbzVi52DdhWXKZ+uB5DqWiYybyns7rSi49faUK\nuVfLxCWvXekwrs5LrmXLlmVNt//HFBjsRrxarWJqaqqrqe90gwnB1Wg0ut7Srrlk81OXyzSHwBWX\n3kx1KZds6jYajU5lYw4fOpSfUTkP8uyKiz1ym7h81cPp6ekOnw8d6ghu4wIC/nUQ3MYFBARkRzAK\nAQEBEQSjEBAQEEEwCgEBARH0yteHFwGMt8/9hKUIeS4D/ZbnXs3vK20C9cTXBwAgok02I6O9hJDn\nctBvee63/OoI3YeAgIAIglEICAiIoJeMwq1znYEcCHkuB/2W537LbwQ9M6YQEBDQG+illkJAQEAP\nYM6NAhG9g4i2ENE2Itow1/mJAxH9g4j+SkSbiWhT+94oEf2KiLa2zyNznMfbiGgfET0h7sXmkYiu\naet9CxFd0EN5/joRjbV1vZmI3tVjeV5DRP9NRE8R0ZNE9O/t+z2ta2vM8ZLpKoC/A1gHYAGAxwCc\nPpd5SsjrPwAs1e59C8CG9vUGAN+c4zy+EcA5AJ5IyyOA09v6HgCwtl0O1R7J89cBfNEQtlfyvBLA\nOe3rYQDPtPPW07q2Pea6pXAegG1Kqe1KqSkAdwO4MCVOL+FCAHe0r+8A8L45zAuUUr8F8JJ2Oy6P\nFwK4Wyk1qZR6FsA2zJRHqYjJcxx6Jc97lFL/r339MoC/AViFHte1LebaKKwCsFP83tW+14tQAB4i\nokeJaH373gql1J729V4AK+Yma4mIy2Ov6/4qInq83b3gZnjP5ZmITgRwNoD/i/7VdQRzbRT6CW9Q\nSp0F4J0AriSiN8o/1Uw7sac/5fRDHtv4D8x0Kc8CsAfADXObHTOIaDGA/wLwOaXUIflfH+m6C3Nt\nFMYArBG/V7fv9RyUUmPt8z4A92Km+fc8Ea0EgPZ539zlMBZxeexZ3SulnldKNZVSLQDfxWxTu2fy\nTER1zBiEu5RSP27f7jtdmzDXRmEjgJOJaC0RLQBwMYD75jhPXSCiISIa5msAbwfwBGby+tF2sI8C\n+Mnc5DARcXm8D8DFRDRARGsBnAzgz3OQvy7wg9XG+zGja6BH8kwz+6/9J4C/KaVuFH/1na6NmOuR\nTgDvwszo7d8BfGWu8xOTx3WYGT1+DMCTnE8AxwF4GMBWAA8BGJ3jfP4AM83tacz0Wz+RlEcAX2nr\nfQuAd/ZQnu8E8FcAj2PmgVrZY3l+A2a6Bo8D2Nw+3tXrurY9wozGgICACOa6+xAQENBjCEYhICAg\ngmAUAgICIghGISAgIIJgFAICAiIIRiEgICCCYBQCAgIiCEYhICAggv8P5s8B1iwc+6oAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea82f47828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "im = Image.open(\"results/fake_samples.png\", \"r\")\n",
    "plt.imshow(np.array(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "83px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
