{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN for MNIST (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arXiv: https://arxiv.org/abs/1511.06434\n",
    "\n",
    "<img src=\"https://lh3.googleusercontent.com/M0D8jzjxyELjUFLVyZYF0UQVuYyLywwIorNRhyOwSeOsATqK_tOZS3cHAnHZSP5I-fmjSCFGB5Ztrxmd7SJpY2amIXOox7H_OVZhGZMqdGk5yUcrDK4Qh5941rMLfW_N67eNAyetS0lB6LlAShsdtqGJCfBrW5a7EBXJnmpM0v640_5-xFDgsxIaC5IliQqSxoz5cYhK14d3tG2V_Qa39CZ4yKlQNnZb0OhWRTezWoFQ3uZdK2RQHQ22PA3CrEW27kTVl95688fhA1EKvZloEZ7YZolxErdsx9Lc3zcE8kiI0gmqErKSsOOImwnL9ESC6rPosze4CSvs8-bSUOLXMyO8fQIDvObuRFfYT6TAflAYSp8PXCevA2LhvUCFat5YV5N6XpFmKoZam6w-lX8koEEeZI6djv8z5eETO3ab1Fhn7_UB1hper6kScrtj_4CRdeP_mvuALhRQvEB81_jV6N5KIFTJ2b7oCoo8to32XZvmk42w6IR8WasMtOQJB3yeKWY5mGAtoLOpuJ4H7r0KAXxbaHpDvltlIR227Ria2-7FSfSJTnaA3bv1MjHpLALaNnelZAwySJynzP0lof8kz9EiQCsjSL2TN-pudLC7jWHnyy-3FAKuj6sK=w807-h208-no\">\n",
    "\n",
    "<img src=\"https://lh3.googleusercontent.com/CqWKmMExGj3Ws9_vYROf2hnnV-HH5hlzvga0Dv_NrHXZKTwoSFWNZ4GO3ee9dVar-kCZmNkpLxkTZ9dLQj9uKeY__ys608i7jfWQqoIRrF2NU-ESZBiWbSxqeEwOICy-W-oWYDAK9Cxse4JPOoWOxFrfaMaNg-cC7UsJCa-PTtt8G11wENorShWIaa2_2dAwn92kaPj8bABqKLRuDEcOxwLdZpnGQOWZPRNgVprefoStGMnfpyRXb9fx-yoBhgSExMv-ybPZLbbymZ8PdMY8bCiNZZ0MRvjvRe-hYGJ_4fWwjmNRaB2ixKLjaaM0Ha2xLA3G_zbpfEo9ygLGIufntEWX6M3mXz-ctK3QrninW3Bfia1IYNQFKJUVnaGvZf6-bFswghn-ody073j89m6fYYysYrVzxxE9HQJeKGuwQKBkG1e7mG1PPwnr-hovxLiHRduMmi0BjNYxOtSYkffBPYzR9n8h66qC-AepoKAGO-Z7LBAuBKpwflhih1Ho9ttBRxBYTwkVeYOMIV8aQkNNY9CKbC-VazHnN7x-eWV0us2tDrJCOcYU3wjBMi-76oalxldFxQQ9MQy1x5SWkiI6vEW_hCbaAlWGJB3bud91PbciIuTk-LIH9Nh4=w805-h350-no\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Convolution GANに以下の改善を行う。\n",
    "- すべてのプーリングレイヤを strided convolutions(discriminator)と fractional-stirided convolutions(generator)に変更する。\n",
    "- generator と discriminator に batchnormを使う。\n",
    "- 全結合隠れ層を取り除く。\n",
    "- ReLU 活性関数を generatorで使う。ただし、output層は tanhを使う。\n",
    "- LeakyReLU活性関数をdiscriminatorのすべての層で使う。\n",
    "\n",
    "もとい！\n",
    "\n",
    "公式チュートリアルにサンプルコードが公開されているので、それを参考に実装する。\n",
    "- [examples/dcgan at master · pytorch/examples](https://github.com/pytorch/examples/tree/master/dcgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    import torch.cuda as t\n",
    "else:\n",
    "    import torch as t\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import normal\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist datasetの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 100\n",
    "sz = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "imagenet_data = ImageFolder('/home/tsu-nera/tmp/av/', \n",
    "                            transform=transforms.Compose([\n",
    "                            transforms.Scale(sz),\n",
    "                            transforms.ToTensor()]))\n",
    "dataloader = torch.utils.data.DataLoader(imagenet_data,\n",
    "                                         batch_size=bs,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nz = 100\n",
    "ngf = 32\n",
    "ndf = 32\n",
    "nc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Discriminater'''\n",
    "class netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(netD, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, 1 , 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.view(100, -1)\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "'''Generator'''\n",
    "class netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(netG, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( ngf,nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(bs,100)\n",
    "        x = self.main(x)\n",
    "        #x = x.view(-1, 1, sz, sz)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteion = nn.BCELoss()\n",
    "net_D = netD()\n",
    "net_G = netG()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    D = net_D.cuda()\n",
    "    G = net_G.cuda()\n",
    "    criteion = criteion.cuda()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netD (\n",
      "  (main): Sequential (\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU (0.2, inplace)\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU (0.2, inplace)\n",
      "    (8): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (9): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netG (\n",
      "  (main): Sequential (\n",
      "    (0): ConvTranspose2d(100, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): Tanh ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(net_D.parameters(), lr = 0.00005)\n",
    "optimizerG = optim.Adam(net_G.parameters(), lr = 0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = t.FloatTensor(bs, nc, sz, sz)\n",
    "noise = t.FloatTensor(normal(0, 1, (bs, 100, 1, 1)))\n",
    "fixed_noise = t.FloatTensor(bs, 100, 1, 1).normal_(0, 1)\n",
    "label = t.FloatTensor(bs)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "input = Variable(input)\n",
    "label = Variable(label)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "niter = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsu-nera/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py:767: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/4000][0/100] Loss_D: 0.4882 Loss_G: 1.5068 D(x): 0.8551 D(G(z)): 0.2698 / 0.2246\n",
      "[0/4000][1/100] Loss_D: 0.4724 Loss_G: 1.5081 D(x): 0.8665 D(G(z)): 0.2716 / 0.2255\n",
      "[0/4000][2/100] Loss_D: 0.5184 Loss_G: 1.4995 D(x): 0.8375 D(G(z)): 0.2737 / 0.2271\n",
      "[0/4000][3/100] Loss_D: 0.5141 Loss_G: 1.4708 D(x): 0.8473 D(G(z)): 0.2815 / 0.2331\n",
      "[0/4000][4/100] Loss_D: 0.4802 Loss_G: 1.5164 D(x): 0.8592 D(G(z)): 0.2713 / 0.2242\n",
      "[0/4000][5/100] Loss_D: 0.4656 Loss_G: 1.5271 D(x): 0.8648 D(G(z)): 0.2681 / 0.2207\n",
      "[0/4000][6/100] Loss_D: 0.4794 Loss_G: 1.5139 D(x): 0.8648 D(G(z)): 0.2714 / 0.2234\n",
      "[0/4000][7/100] Loss_D: 0.5010 Loss_G: 1.5124 D(x): 0.8474 D(G(z)): 0.2732 / 0.2248\n",
      "[0/4000][8/100] Loss_D: 0.4937 Loss_G: 1.5078 D(x): 0.8573 D(G(z)): 0.2747 / 0.2256\n",
      "[0/4000][9/100] Loss_D: 0.5028 Loss_G: 1.4957 D(x): 0.8494 D(G(z)): 0.2785 / 0.2285\n",
      "[0/4000][10/100] Loss_D: 0.4759 Loss_G: 1.5459 D(x): 0.8566 D(G(z)): 0.2667 / 0.2180\n",
      "[0/4000][11/100] Loss_D: 0.5011 Loss_G: 1.5604 D(x): 0.8394 D(G(z)): 0.2633 / 0.2149\n",
      "[0/4000][12/100] Loss_D: 0.5216 Loss_G: 1.5143 D(x): 0.8417 D(G(z)): 0.2738 / 0.2237\n",
      "[0/4000][13/100] Loss_D: 0.5185 Loss_G: 1.5712 D(x): 0.8246 D(G(z)): 0.2595 / 0.2117\n",
      "[0/4000][14/100] Loss_D: 0.4697 Loss_G: 1.6012 D(x): 0.8434 D(G(z)): 0.2516 / 0.2054\n",
      "[0/4000][15/100] Loss_D: 0.4683 Loss_G: 1.5963 D(x): 0.8465 D(G(z)): 0.2522 / 0.2060\n",
      "[0/4000][16/100] Loss_D: 0.4527 Loss_G: 1.6319 D(x): 0.8494 D(G(z)): 0.2442 / 0.1992\n",
      "[0/4000][17/100] Loss_D: 0.4979 Loss_G: 1.6399 D(x): 0.8212 D(G(z)): 0.2420 / 0.1978\n",
      "[0/4000][18/100] Loss_D: 0.4980 Loss_G: 1.6216 D(x): 0.8228 D(G(z)): 0.2457 / 0.2012\n",
      "[0/4000][19/100] Loss_D: 0.5240 Loss_G: 1.6147 D(x): 0.8095 D(G(z)): 0.2472 / 0.2025\n",
      "[0/4000][20/100] Loss_D: 0.4562 Loss_G: 1.6667 D(x): 0.8414 D(G(z)): 0.2362 / 0.1930\n",
      "[0/4000][21/100] Loss_D: 0.4595 Loss_G: 1.6801 D(x): 0.8377 D(G(z)): 0.2331 / 0.1906\n",
      "[0/4000][22/100] Loss_D: 0.4506 Loss_G: 1.6887 D(x): 0.8401 D(G(z)): 0.2306 / 0.1885\n",
      "[0/4000][23/100] Loss_D: 0.4707 Loss_G: 1.6940 D(x): 0.8256 D(G(z)): 0.2296 / 0.1876\n",
      "[0/4000][24/100] Loss_D: 0.4298 Loss_G: 1.6923 D(x): 0.8545 D(G(z)): 0.2308 / 0.1886\n",
      "[0/4000][25/100] Loss_D: 0.4541 Loss_G: 1.7059 D(x): 0.8376 D(G(z)): 0.2266 / 0.1845\n",
      "[0/4000][26/100] Loss_D: 0.4353 Loss_G: 1.7288 D(x): 0.8438 D(G(z)): 0.2228 / 0.1812\n",
      "[0/4000][27/100] Loss_D: 0.4664 Loss_G: 1.7076 D(x): 0.8316 D(G(z)): 0.2277 / 0.1852\n",
      "[0/4000][28/100] Loss_D: 0.4424 Loss_G: 1.7313 D(x): 0.8420 D(G(z)): 0.2229 / 0.1811\n",
      "[0/4000][29/100] Loss_D: 0.4430 Loss_G: 1.7407 D(x): 0.8348 D(G(z)): 0.2213 / 0.1796\n",
      "[0/4000][30/100] Loss_D: 0.4527 Loss_G: 1.7527 D(x): 0.8294 D(G(z)): 0.2182 / 0.1769\n",
      "[0/4000][31/100] Loss_D: 0.4502 Loss_G: 1.8007 D(x): 0.8218 D(G(z)): 0.2094 / 0.1695\n",
      "[0/4000][32/100] Loss_D: 0.4558 Loss_G: 1.7875 D(x): 0.8220 D(G(z)): 0.2110 / 0.1711\n",
      "[0/4000][33/100] Loss_D: 0.4068 Loss_G: 1.8020 D(x): 0.8520 D(G(z)): 0.2081 / 0.1684\n",
      "[0/4000][34/100] Loss_D: 0.4325 Loss_G: 1.8213 D(x): 0.8299 D(G(z)): 0.2042 / 0.1650\n",
      "[0/4000][35/100] Loss_D: 0.4494 Loss_G: 1.8283 D(x): 0.8147 D(G(z)): 0.2028 / 0.1639\n",
      "[0/4000][36/100] Loss_D: 0.4073 Loss_G: 1.8494 D(x): 0.8434 D(G(z)): 0.1992 / 0.1607\n",
      "[0/4000][37/100] Loss_D: 0.4271 Loss_G: 1.8422 D(x): 0.8323 D(G(z)): 0.2006 / 0.1620\n",
      "[0/4000][38/100] Loss_D: 0.4383 Loss_G: 1.8648 D(x): 0.8188 D(G(z)): 0.1967 / 0.1590\n",
      "[0/4000][39/100] Loss_D: 0.3918 Loss_G: 1.8383 D(x): 0.8557 D(G(z)): 0.2018 / 0.1630\n",
      "[0/4000][40/100] Loss_D: 0.3907 Loss_G: 1.8936 D(x): 0.8516 D(G(z)): 0.1922 / 0.1548\n",
      "[0/4000][41/100] Loss_D: 0.4294 Loss_G: 1.9185 D(x): 0.8198 D(G(z)): 0.1858 / 0.1500\n",
      "[0/4000][42/100] Loss_D: 0.3917 Loss_G: 1.8990 D(x): 0.8463 D(G(z)): 0.1901 / 0.1536\n",
      "[0/4000][43/100] Loss_D: 0.4060 Loss_G: 1.9402 D(x): 0.8323 D(G(z)): 0.1811 / 0.1467\n",
      "[0/4000][44/100] Loss_D: 0.4007 Loss_G: 1.9381 D(x): 0.8381 D(G(z)): 0.1820 / 0.1475\n",
      "[0/4000][45/100] Loss_D: 0.3663 Loss_G: 1.9535 D(x): 0.8552 D(G(z)): 0.1799 / 0.1456\n",
      "[0/4000][46/100] Loss_D: 0.3876 Loss_G: 1.9929 D(x): 0.8388 D(G(z)): 0.1726 / 0.1402\n",
      "[0/4000][47/100] Loss_D: 0.3505 Loss_G: 1.9732 D(x): 0.8627 D(G(z)): 0.1759 / 0.1428\n",
      "[0/4000][48/100] Loss_D: 0.3521 Loss_G: 2.0454 D(x): 0.8575 D(G(z)): 0.1646 / 0.1339\n",
      "[0/4000][49/100] Loss_D: 0.3435 Loss_G: 2.0233 D(x): 0.8639 D(G(z)): 0.1677 / 0.1365\n",
      "[0/4000][50/100] Loss_D: 0.3651 Loss_G: 2.0339 D(x): 0.8459 D(G(z)): 0.1656 / 0.1350\n",
      "[0/4000][51/100] Loss_D: 0.3601 Loss_G: 2.0676 D(x): 0.8528 D(G(z)): 0.1589 / 0.1299\n",
      "[0/4000][52/100] Loss_D: 0.3569 Loss_G: 2.0430 D(x): 0.8518 D(G(z)): 0.1624 / 0.1330\n",
      "[0/4000][53/100] Loss_D: 0.3341 Loss_G: 2.0537 D(x): 0.8671 D(G(z)): 0.1621 / 0.1329\n",
      "[0/4000][54/100] Loss_D: 0.3184 Loss_G: 2.0756 D(x): 0.8762 D(G(z)): 0.1586 / 0.1301\n",
      "[0/4000][55/100] Loss_D: 0.3836 Loss_G: 2.0360 D(x): 0.8344 D(G(z)): 0.1641 / 0.1352\n",
      "[0/4000][56/100] Loss_D: 0.3355 Loss_G: 2.0542 D(x): 0.8670 D(G(z)): 0.1607 / 0.1323\n",
      "[0/4000][57/100] Loss_D: 0.3408 Loss_G: 2.0762 D(x): 0.8565 D(G(z)): 0.1563 / 0.1284\n",
      "[0/4000][58/100] Loss_D: 0.3280 Loss_G: 2.0208 D(x): 0.8759 D(G(z)): 0.1660 / 0.1367\n",
      "[0/4000][59/100] Loss_D: 0.3266 Loss_G: 2.0285 D(x): 0.8741 D(G(z)): 0.1645 / 0.1353\n",
      "[0/4000][60/100] Loss_D: 0.3551 Loss_G: 1.9921 D(x): 0.8624 D(G(z)): 0.1719 / 0.1413\n",
      "[0/4000][61/100] Loss_D: 0.3389 Loss_G: 1.9636 D(x): 0.8736 D(G(z)): 0.1764 / 0.1444\n",
      "[0/4000][62/100] Loss_D: 0.3628 Loss_G: 1.9648 D(x): 0.8597 D(G(z)): 0.1771 / 0.1448\n",
      "[0/4000][63/100] Loss_D: 0.3591 Loss_G: 1.9481 D(x): 0.8677 D(G(z)): 0.1808 / 0.1472\n",
      "[0/4000][64/100] Loss_D: 0.3688 Loss_G: 1.8963 D(x): 0.8737 D(G(z)): 0.1927 / 0.1562\n",
      "[0/4000][65/100] Loss_D: 0.3532 Loss_G: 1.9144 D(x): 0.8781 D(G(z)): 0.1901 / 0.1527\n",
      "[0/4000][66/100] Loss_D: 0.3676 Loss_G: 1.8639 D(x): 0.8797 D(G(z)): 0.2013 / 0.1604\n",
      "[0/4000][67/100] Loss_D: 0.3945 Loss_G: 1.8657 D(x): 0.8640 D(G(z)): 0.2009 / 0.1591\n",
      "[0/4000][68/100] Loss_D: 0.3743 Loss_G: 1.8242 D(x): 0.8835 D(G(z)): 0.2123 / 0.1669\n",
      "[0/4000][69/100] Loss_D: 0.4160 Loss_G: 1.8318 D(x): 0.8587 D(G(z)): 0.2128 / 0.1667\n",
      "[0/4000][70/100] Loss_D: 0.4521 Loss_G: 1.7623 D(x): 0.8521 D(G(z)): 0.2283 / 0.1786\n",
      "[0/4000][71/100] Loss_D: 0.4026 Loss_G: 1.7882 D(x): 0.8730 D(G(z)): 0.2249 / 0.1746\n",
      "[0/4000][72/100] Loss_D: 0.4276 Loss_G: 1.7452 D(x): 0.8638 D(G(z)): 0.2338 / 0.1807\n",
      "[0/4000][73/100] Loss_D: 0.4411 Loss_G: 1.7356 D(x): 0.8556 D(G(z)): 0.2371 / 0.1820\n",
      "[0/4000][74/100] Loss_D: 0.4600 Loss_G: 1.7474 D(x): 0.8455 D(G(z)): 0.2358 / 0.1803\n",
      "[0/4000][75/100] Loss_D: 0.4602 Loss_G: 1.7480 D(x): 0.8424 D(G(z)): 0.2373 / 0.1816\n",
      "[0/4000][76/100] Loss_D: 0.5055 Loss_G: 1.6947 D(x): 0.8300 D(G(z)): 0.2490 / 0.1912\n",
      "[0/4000][77/100] Loss_D: 0.4737 Loss_G: 1.6919 D(x): 0.8427 D(G(z)): 0.2486 / 0.1894\n",
      "[0/4000][78/100] Loss_D: 0.4704 Loss_G: 1.7075 D(x): 0.8439 D(G(z)): 0.2468 / 0.1873\n",
      "[0/4000][79/100] Loss_D: 0.5308 Loss_G: 1.6737 D(x): 0.8079 D(G(z)): 0.2538 / 0.1931\n",
      "[0/4000][80/100] Loss_D: 0.5464 Loss_G: 1.6569 D(x): 0.8144 D(G(z)): 0.2576 / 0.1959\n",
      "[0/4000][81/100] Loss_D: 0.5500 Loss_G: 1.6495 D(x): 0.8068 D(G(z)): 0.2593 / 0.1976\n",
      "[0/4000][82/100] Loss_D: 0.5575 Loss_G: 1.6320 D(x): 0.7967 D(G(z)): 0.2623 / 0.1991\n",
      "[0/4000][83/100] Loss_D: 0.5305 Loss_G: 1.6241 D(x): 0.8148 D(G(z)): 0.2649 / 0.2012\n",
      "[0/4000][84/100] Loss_D: 0.5269 Loss_G: 1.6234 D(x): 0.8186 D(G(z)): 0.2653 / 0.2018\n",
      "[0/4000][85/100] Loss_D: 0.5359 Loss_G: 1.6767 D(x): 0.8033 D(G(z)): 0.2513 / 0.1911\n",
      "[0/4000][86/100] Loss_D: 0.5088 Loss_G: 1.7148 D(x): 0.8137 D(G(z)): 0.2428 / 0.1845\n",
      "[0/4000][87/100] Loss_D: 0.5429 Loss_G: 1.7645 D(x): 0.7819 D(G(z)): 0.2297 / 0.1755\n",
      "[0/4000][88/100] Loss_D: 0.5779 Loss_G: 1.7618 D(x): 0.7583 D(G(z)): 0.2284 / 0.1763\n",
      "[0/4000][89/100] Loss_D: 0.4927 Loss_G: 1.7723 D(x): 0.8078 D(G(z)): 0.2241 / 0.1738\n",
      "[0/4000][90/100] Loss_D: 0.4973 Loss_G: 1.7989 D(x): 0.7956 D(G(z)): 0.2176 / 0.1698\n",
      "[0/4000][91/100] Loss_D: 0.4702 Loss_G: 1.8352 D(x): 0.8095 D(G(z)): 0.2093 / 0.1634\n",
      "[0/4000][92/100] Loss_D: 0.4416 Loss_G: 1.9093 D(x): 0.8135 D(G(z)): 0.1938 / 0.1515\n",
      "[0/4000][93/100] Loss_D: 0.4497 Loss_G: 1.9148 D(x): 0.8042 D(G(z)): 0.1908 / 0.1501\n",
      "[0/4000][94/100] Loss_D: 0.4354 Loss_G: 1.9216 D(x): 0.8174 D(G(z)): 0.1895 / 0.1496\n",
      "[0/4000][95/100] Loss_D: 0.3657 Loss_G: 1.9973 D(x): 0.8554 D(G(z)): 0.1763 / 0.1390\n",
      "[0/4000][96/100] Loss_D: 0.4222 Loss_G: 1.9540 D(x): 0.8240 D(G(z)): 0.1840 / 0.1458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/4000][97/100] Loss_D: 0.4212 Loss_G: 1.9638 D(x): 0.8270 D(G(z)): 0.1821 / 0.1441\n",
      "[0/4000][98/100] Loss_D: 0.3893 Loss_G: 2.0056 D(x): 0.8344 D(G(z)): 0.1747 / 0.1377\n",
      "[0/4000][99/100] Loss_D: 0.4132 Loss_G: 2.0207 D(x): 0.8153 D(G(z)): 0.1712 / 0.1355\n",
      "[1/4000][0/100] Loss_D: 0.4075 Loss_G: 2.0052 D(x): 0.8357 D(G(z)): 0.1749 / 0.1386\n",
      "[1/4000][1/100] Loss_D: 0.3879 Loss_G: 1.9962 D(x): 0.8380 D(G(z)): 0.1759 / 0.1391\n",
      "[1/4000][2/100] Loss_D: 0.3910 Loss_G: 1.9693 D(x): 0.8438 D(G(z)): 0.1813 / 0.1430\n",
      "[1/4000][3/100] Loss_D: 0.3717 Loss_G: 2.0436 D(x): 0.8543 D(G(z)): 0.1689 / 0.1324\n",
      "[1/4000][4/100] Loss_D: 0.3664 Loss_G: 2.0522 D(x): 0.8474 D(G(z)): 0.1690 / 0.1324\n",
      "[1/4000][5/100] Loss_D: 0.3472 Loss_G: 2.0677 D(x): 0.8609 D(G(z)): 0.1667 / 0.1298\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-5027f65d058e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0merrG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0merrG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mD_G_z2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moptimizerG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real (data)\n",
    "        net_D.zero_grad()\n",
    "        real, _ = data\n",
    "        input.data.resize_(real.size()).copy_(real)\n",
    "        label.data.resize_(bs).fill_(real_label)\n",
    "        output = net_D(input)\n",
    "        errD_real = criteion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        #train with fake (generated)\n",
    "        noise.data.resize_(bs, 100, 1, 1)\n",
    "        noise.data.normal_(0, 1)\n",
    "        fake = net_G(noise)\n",
    "        label.data.fill_(fake_label)\n",
    "        output = net_D(fake.detach())\n",
    "        errD_fake = criteion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        net_G.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = net_D(fake)\n",
    "        errG = criteion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.data.mean()\n",
    "        optimizerG.step()\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, niter, i, len(dataloader),\n",
    "                 errD.data[0], errG.data[0],  D_x, D_G_z1, D_G_z2))\n",
    "    if epoch % 10 == 0:\n",
    "        fake = net_G(fixed_noise)\n",
    "        vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png'\n",
    "                              % ('results', epoch),normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = net_G(fixed_noise)\n",
    "vutils.save_image(fake.data[:64], '%s/fake_samples4.png' % 'results' ,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open(\"results/fake_samples4.png\", \"r\")\n",
    "plt.imshow(np.array(im))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "83px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
